# Introdu√ß√£o

Hoje vamos aprender o que √© raspagem de dados e o que podemos fazer utilizando esta t√©cnica. Vamos ver tamb√©m como fazer requisi√ß√µes web, analisando suas respostas e extraindo dados. Por fim, tamb√©m veremos t√©cnicas para evitar problemas com essa pr√°tica.

## Voc√™ ser√° capaz de:
Realizar requisi√ß√µes web;

Analisar conte√∫dos HTML para extrair dados;

Aplicar t√©cnicas de raspagem para evitar problemas como bloqueio de acesso;

Armazenar os dados obtidos em um banco de dados.

## Por que isso √© importante?
Imagine que voc√™ queira fazer compara√ß√µes de pre√ßos e informa√ß√µes, ou talvez descobrir informa√ß√µes sobre algum assunto. Por√©m todos os dados a respeito do seu assunto de interesse n√£o est√£o estruturados, sendo exibidos somente em uma p√°gina web. Pois √©, uma p√°gina web pode ser √∫til para humanos, mas certamente n√£o √© √∫til para fazermos an√°lises estruturadas.

A raspagem de dados tem sido muito √∫til em trabalhos jornal√≠sticos, fornecendo dados para embasar mat√©rias, mas tamb√©m pode ser √∫til para outros fins, como comparar pre√ßos de produtos com a concorr√™ncia; automatiza√ß√£o de processos ma√ßantes como buscar artigos cient√≠ficos em bases acad√™micas; recupera√ß√£o de documentos em sites jur√≠dicos; analisar perfis de redes sociais; recuperar dados p√∫blicos do governo e muitos outros lugares.

## O que √© raspagem de dados?

Raspagem de dados √© uma t√©cnica computacional para extrair dados provenientes de um servi√ßo ou aplica√ß√£o, estruturando-os em bancos de dados, planilhas ou outros formatos. Essa t√©cnica consiste em extrair dados de sites e transport√°-los para um formato mais simples e male√°vel para que possam ser analisados e cruzados com mais facilidade.

Alguns passos aplicados nesta t√©cnica s√£o: realiza√ß√£o de requisi√ß√µes, an√°lise das respostas e extra√ß√£o dos dados, navega√ß√£o do conte√∫do, limpeza e armazenamento dos dados.

Agora vamos ao ver passo a passo como fazer raspagem de dados, prevenindo erros que podem acontecer. üí™

## Requisi√ß√µes web

A comunica√ß√£o com servidores HTTP e HTTPS se d√° atrav√©s de requisi√ß√µes, nas quais utilizamos o verbo para indicar que tipo de a√ß√£o deve ser tomada para um dado recurso. Devemos informar na requisi√ß√£o em qual recurso estamos atuando e no cabe√ßalho passamos algumas informa√ß√µes que podem ser importantes, como o tipo de resposta aceita ou o tipo de conte√∫do sendo enviado.

O Python possui um pacote para lidar com o protocolo HTTP o urllib, por√©m seu uso √© mais verboso. Por isso vamos utilizar a biblioteca requests, que possui uma interface mais amig√°vel e √© bem difundida na comunidade.

Voc√™ j√° pode instalar a requests dentro de um ambiente virtual, com os seguintes comandos:

````
python3 -m venv .venv && source .venv/bin/activate
python3 -m pip install requests
````

## Rate Limit
Muitas vezes a p√°gina de onde estamos removendo o conte√∫do possui uma limita√ß√£o de quantas requisi√ß√µes podemos enviar em um curto per√≠odo de tempo, evitando assim ataques de nega√ß√£o de servi√ßo.

Isto pode levar a um bloqueio por um curto per√≠odo de tempo ou at√© mesmo banimento de acessar um recurso.

Uma boa pr√°tica √© sempre fazermos uma pausa entre as requisi√ß√µes, ou lote delas, mesmo que o website onde a informa√ß√£o est√° n√£o fa√ßa o bloqueio. Assim, evitamos tirar o site do ar.

````
import requests
import time


# Coloca uma pausa de 6 segundos a cada requisi√ß√£o
# Obs: este site de exemplo tem um rate limit de 10 requisi√ß√µes por minuto
for _ in range(15):
    response = requests.get("https://www.cloudflare.com/rate-limit-test/")
    print(response)
    time.sleep(6)
````

## Timeout
√Ås vezes pedimos um recurso ao servidor, mas caso o nosso tr√°fego de rede esteja lento ou exista um problema interno do servidor, nossa resposta pode demorar ou at√© mesmo ficar travada indefinidamente.

Como garantir, ap√≥s um tempo, que o recurso seja retornado? ü§î

````
import requests


try:
    # recurso demora muito a responder
    response = requests.get("http://httpbin.org/delay/10", timeout=2)
except requests.ReadTimeout:
    # vamos fazer uma nova requisi√ß√£o
    response = requests.get("http://httpbin.org/delay/1", timeout=2)
finally:
    print(response.status_code)
````

## Analisando respostas

Para realizar a extra√ß√£o de dados de um conte√∫do web vamos utilizar uma biblioteca chamada parsel. Ela pode ser instalada com o comando o comando abaixo: